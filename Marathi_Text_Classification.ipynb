{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "cVJV0Z5oBWY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Marathi text.csv')"
      ],
      "metadata": {
        "id": "_WTYEFXd2NE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78W6M1QbBkcT",
        "outputId": "0e4588fa-b4ef-4d56-d017-2da19996b79c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    1. \"क्रिकेटमध्ये आज भारताने जोरदार विजय मिळवला.\"  Sports\n",
            "0  2. \"खेळाडूंनी परिश्रम घेत जिंकलेले सामने नेहमी...  Sports\n",
            "1  3. \"फुटबॉल खेळताना वेग आणि तंत्रज्ञान महत्त्वा...  Sports\n",
            "2  4. \"खिलाडूवृत्ती दाखवणारे खेळाडू नेहमीच कौतुका...  Sports\n",
            "3          5. \"कबड्डी हा भारताचा पारंपारिक खेळ आहे.\"  Sports\n",
            "4  6. \"टेनिसमध्ये रॅकेटचा योग्य वापर विजयासाठी मह...  Sports\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyyIZLLgBlo9",
        "outputId": "3f5d2a3b-70a1-4eae-c49a-00c75544eb4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. \"क्रिकेटमध्ये आज भारताने जोरदार विजय मिळवला.\"    0\n",
            "Sports                                              0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weUYJd9iBntt",
        "outputId": "7a3a54eb-218a-4349-bb32-587e7a744b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         1. \"क्रिकेटमध्ये आज भारताने जोरदार विजय मिळवला.\"   Sports\n",
            "count                                                5099     5099\n",
            "unique                                               4021       17\n",
            "top     \"संपत्तीत भौगोलिक स्थानाचा प्रभाव महत्त्वाचा अ...  Science\n",
            "freq                                                   15      300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk scikit-learn indic-nlp-library\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "V_4O4NX6Bepm",
        "outputId": "f16c1997-6ca0-4d1a-807d-f072b1ecdcb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Collecting indic-nlp-library\n",
            "  Downloading indic_nlp_library-0.92-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Collecting sphinx-argparse (from indic-nlp-library)\n",
            "  Downloading sphinx_argparse-0.5.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting sphinx-rtd-theme (from indic-nlp-library)\n",
            "  Downloading sphinx_rtd_theme-3.0.1-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting morfessor (from indic-nlp-library)\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2024.2)\n",
            "Collecting sphinx>=5.1.0 (from sphinx-argparse->indic-nlp-library)\n",
            "  Downloading sphinx-8.1.3-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting docutils>=0.19 (from sphinx-argparse->indic-nlp-library)\n",
            "  Downloading docutils-0.21.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->indic-nlp-library)\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.16.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: Jinja2>=3.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.4)\n",
            "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.18.0)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.16.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (0.7.16)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.30.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.32.3)\n",
            "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (24.1)\n",
            "Requirement already satisfied: tomli>=2 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2024.8.30)\n",
            "Downloading indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Downloading sphinx_argparse-0.5.2-py3-none-any.whl (12 kB)\n",
            "Downloading sphinx_rtd_theme-3.0.1-py2.py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docutils-0.21.2-py3-none-any.whl (587 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.4/587.4 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinx-8.1.3-py3-none-any.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: morfessor, docutils, sphinx, sphinxcontrib-jquery, sphinx-argparse, sphinx-rtd-theme, indic-nlp-library\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.18.1\n",
            "    Uninstalling docutils-0.18.1:\n",
            "      Successfully uninstalled docutils-0.18.1\n",
            "  Attempting uninstall: sphinx\n",
            "    Found existing installation: Sphinx 5.0.2\n",
            "    Uninstalling Sphinx-5.0.2:\n",
            "      Successfully uninstalled Sphinx-5.0.2\n",
            "Successfully installed docutils-0.21.2 indic-nlp-library-0.92 morfessor-2.0.6 sphinx-8.1.3 sphinx-argparse-0.5.2 sphinx-rtd-theme-3.0.1 sphinxcontrib-jquery-4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "marathi_stopwords = set([\n",
        "    'आणि', 'तो', 'त्यांना', 'यासाठी', 'किंवा', 'हे', 'ही', 'हाच',\n",
        "    'त्या', 'तिचे', 'पण', 'माझे', 'तुम्ही', 'आहे', 'आहेत', 'असे',\n",
        "    'तरी', 'असणे', 'जर', 'तुम्ही', 'होईल', 'कस', 'सर्व', 'अनेक',\n",
        "    'जण', 'अनेक', 'मुळे', 'पुन्हा', 'असताना', 'तसा', 'असले',\n",
        "    'सुधा', 'जसे', 'नाही', 'ज्या', 'म्हणजे', 'केल्याने', 'तुम्ही',\n",
        "    'म्हणजे', 'संपूर्ण', 'यावर', 'म्हणजे', 'या', 'त्याचे', 'विषय',\n",
        "    'माझा', 'जरी', 'आहेत', 'हे', 'तिथे', 'तुम्हाला', 'तर',\n",
        "    'असेच', 'आणखी', 'मूलतः', 'किंवा', 'रोज', 'त्यांच्यामुळे',\n",
        "    'वापर', 'असावा', 'वापरून', 'असलेले', 'फार', 'अधूनमधून',\n",
        "    'असणे', 'गेल्या', 'बद्दल', 'एक', 'तरी', 'कृपया', 'असो',\n",
        "    'खूप', 'शक्य', 'तुम्ही', 'नाही', 'किंवा', 'याने', 'वर्तमान',\n",
        "    'सर्वसाधारण', 'आहे', 'अजून', 'अशा', 'तुम्ही', 'अशा',\n",
        "    'जसा', 'असे', 'ते', 'विनंती', 'आपण', 'येथे', 'तुम्ही',\n",
        "    'सहा', 'नक्की', 'तुम्ही', 'गेल्यादिवशी', 'ज्यांना', 'त्याचे',\n",
        "    'म्हणजे', 'आपल्याला', 'त्यांना', 'यावर', 'त्यांना',\n",
        "    'असलेले', 'आपले', 'म्हणजे', 'वेळी', 'त्यावर', 'तरीही'\n",
        "])"
      ],
      "metadata": {
        "id": "bMkQNHmzDEkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data (assuming df is already loaded)\n",
        "# Rename the columns for better understanding\n",
        "df.columns = ['Text', 'Category']\n",
        "\n",
        "# Display the updated DataFrame with a clearer output format\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Updated DataFrame:\")\n",
        "print(df.head(), \"\\n\")  # Print the first few rows of the DataFrame\n",
        "\n",
        "# Get the description of the 'Text' column to find unique counts and top values\n",
        "text_description = df['Text'].describe()\n",
        "\n",
        "# If you want to show the number of unique values and top value explicitly\n",
        "print(\"\\nAdditional Information:\")\n",
        "print(f\"Number of unique texts: {text_description['unique']}\")\n",
        "print(f\"Most frequent text: '{text_description['top']}' (appears {text_description['freq']} times)\")\n",
        "print(\"=\"*50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPRufXnCTFz2",
        "outputId": "868a0cd2-781a-4283-ce8a-04764cee4bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Updated DataFrame:\n",
            "                                                Text Category\n",
            "0  2. \"खेळाडूंनी परिश्रम घेत जिंकलेले सामने नेहमी...   Sports\n",
            "1  3. \"फुटबॉल खेळताना वेग तंत्रज्ञान महत्त्वाचे ठ...   Sports\n",
            "2  4. \"खिलाडूवृत्ती दाखवणारे खेळाडू नेहमीच कौतुका...   Sports\n",
            "3          5. \"कबड्डी हा भारताचा पारंपारिक खेळ आहे.\"   Sports\n",
            "4  6. \"टेनिसमध्ये रॅकेटचा योग्य विजयासाठी महत्वाच...   Sports \n",
            "\n",
            "\n",
            "Additional Information:\n",
            "Number of unique texts: 4019\n",
            "Most frequent text: '\"संपत्तीत भौगोलिक स्थानाचा प्रभाव महत्त्वाचा असतो.\"' (appears 15 times)\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # Tokenize and remove stopwords\n",
        "    words = [word for word in text.split() if word not in marathi_stopwords]\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Apply the preprocessing function to the 'Text' column\n",
        "df['Text'] = df['Text'].apply(preprocess_text)\n",
        "\n",
        "# Verify preprocessing\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wosCI_sCDX9c",
        "outputId": "3838e102-c6ec-472c-cab8-1ec16ad49dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Text Category\n",
            "0  2. \"खेळाडूंनी परिश्रम घेत जिंकलेले सामने नेहमी...   Sports\n",
            "1  3. \"फुटबॉल खेळताना वेग तंत्रज्ञान महत्त्वाचे ठ...   Sports\n",
            "2  4. \"खिलाडूवृत्ती दाखवणारे खेळाडू नेहमीच कौतुका...   Sports\n",
            "3          5. \"कबड्डी हा भारताचा पारंपारिक खेळ आहे.\"   Sports\n",
            "4  6. \"टेनिसमध्ये रॅकेटचा योग्य विजयासाठी महत्वाच...   Sports\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert text into numerical form using TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=5000)  # Limit to 5000 most important features\n",
        "X = vectorizer.fit_transform(df['Text']).toarray()"
      ],
      "metadata": {
        "id": "ag2cvKK1D2cB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the 'Category' labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['Category'])"
      ],
      "metadata": {
        "id": "EnHYSLwsD_L_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "5-BE3rAhEDQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes**"
      ],
      "metadata": {
        "id": "gusgbGYEEKHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Initialize the model\n",
        "nb_model = MultinomialNB()\n",
        "\n",
        "# Train the model\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_nb = nb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
        "print(\"Naive Bayes Classification Report:\\n\", classification_report(y_test, y_pred_nb))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNZlllvsEQXt",
        "outputId": "5eb3bca6-7f92-4da1-afdd-9f44eb312805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 0.8245098039215686\n",
            "Naive Bayes Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.83      0.67        47\n",
            "           1       0.75      0.67      0.71        54\n",
            "           2       0.94      1.00      0.97        58\n",
            "           3       0.74      0.88      0.81        69\n",
            "           4       0.79      0.72      0.75        53\n",
            "           5       0.79      0.74      0.77        62\n",
            "           6       0.87      0.69      0.77        59\n",
            "           7       0.85      0.84      0.85        56\n",
            "           8       0.69      0.62      0.65        58\n",
            "           9       0.89      0.98      0.94        60\n",
            "          10       0.79      0.83      0.81        65\n",
            "          11       0.86      0.84      0.85        61\n",
            "          12       0.96      0.86      0.91        74\n",
            "          13       0.90      0.81      0.85        68\n",
            "          14       0.85      0.98      0.91        61\n",
            "          15       0.89      0.76      0.82        63\n",
            "          16       0.92      0.92      0.92        52\n",
            "\n",
            "    accuracy                           0.82      1020\n",
            "   macro avg       0.83      0.82      0.82      1020\n",
            "weighted avg       0.83      0.82      0.82      1020\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression**"
      ],
      "metadata": {
        "id": "Og5yixSsEUui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Initialize the model\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(\"Logistic Regression Classification Report:\\n\", classification_report(y_test, y_pred_lr))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l41Av4ATEbvJ",
        "outputId": "358c9ec6-1993-43fe-e0f2-caffa28db66b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.8696078431372549\n",
            "Logistic Regression Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.74      0.69        47\n",
            "           1       0.80      0.74      0.77        54\n",
            "           2       0.98      1.00      0.99        58\n",
            "           3       0.88      0.97      0.92        69\n",
            "           4       0.73      0.83      0.78        53\n",
            "           5       0.82      0.79      0.80        62\n",
            "           6       0.79      0.83      0.81        59\n",
            "           7       0.91      0.86      0.88        56\n",
            "           8       0.75      0.69      0.72        58\n",
            "           9       0.98      1.00      0.99        60\n",
            "          10       0.93      0.88      0.90        65\n",
            "          11       0.89      0.84      0.86        61\n",
            "          12       0.92      0.88      0.90        74\n",
            "          13       0.93      0.93      0.93        68\n",
            "          14       0.91      0.98      0.94        61\n",
            "          15       0.93      0.81      0.86        63\n",
            "          16       0.93      0.96      0.94        52\n",
            "\n",
            "    accuracy                           0.87      1020\n",
            "   macro avg       0.87      0.87      0.87      1020\n",
            "weighted avg       0.87      0.87      0.87      1020\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest Classifier**"
      ],
      "metadata": {
        "id": "I0TDXejTEhlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frDynebaEmhE",
        "outputId": "24d3be72-c36e-4e06-d719-c452f7f544e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.8509803921568627\n",
            "Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.79      0.76        47\n",
            "           1       0.86      0.78      0.82        54\n",
            "           2       0.98      1.00      0.99        58\n",
            "           3       0.92      0.94      0.93        69\n",
            "           4       0.68      0.85      0.76        53\n",
            "           5       0.77      0.71      0.74        62\n",
            "           6       0.73      0.76      0.74        59\n",
            "           7       0.85      0.84      0.85        56\n",
            "           8       0.72      0.72      0.72        58\n",
            "           9       0.95      0.97      0.96        60\n",
            "          10       0.88      0.82      0.85        65\n",
            "          11       0.90      0.92      0.91        61\n",
            "          12       0.91      0.80      0.85        74\n",
            "          13       0.85      0.85      0.85        68\n",
            "          14       0.91      0.98      0.94        61\n",
            "          15       0.86      0.78      0.82        63\n",
            "          16       0.94      0.96      0.95        52\n",
            "\n",
            "    accuracy                           0.85      1020\n",
            "   macro avg       0.85      0.85      0.85      1020\n",
            "weighted avg       0.85      0.85      0.85      1020\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM**"
      ],
      "metadata": {
        "id": "JiZP8EaJEsxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize the model\n",
        "svm_model = SVC(kernel='linear')\n",
        "\n",
        "# Train the model\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(\"SVM Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3neftvvJEy5F",
        "outputId": "363a506a-b3d9-4528-abd6-2e4baa20d6bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.8735294117647059\n",
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.79      0.72        47\n",
            "           1       0.81      0.80      0.80        54\n",
            "           2       0.97      1.00      0.98        58\n",
            "           3       0.93      0.94      0.94        69\n",
            "           4       0.71      0.83      0.77        53\n",
            "           5       0.75      0.84      0.79        62\n",
            "           6       0.80      0.81      0.81        59\n",
            "           7       0.92      0.86      0.89        56\n",
            "           8       0.75      0.78      0.76        58\n",
            "           9       0.97      0.97      0.97        60\n",
            "          10       0.92      0.85      0.88        65\n",
            "          11       0.93      0.85      0.89        61\n",
            "          12       0.99      0.89      0.94        74\n",
            "          13       0.93      0.91      0.92        68\n",
            "          14       0.92      0.97      0.94        61\n",
            "          15       0.92      0.78      0.84        63\n",
            "          16       0.98      0.96      0.97        52\n",
            "\n",
            "    accuracy                           0.87      1020\n",
            "   macro avg       0.87      0.87      0.87      1020\n",
            "weighted avg       0.88      0.87      0.88      1020\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model Comparison:\")\n",
        "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ip0Tc7amE2Ga",
        "outputId": "6e9667be-deae-4131-b4d1-7f7c28e317a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Comparison:\n",
            "Naive Bayes Accuracy: 0.8245098039215686\n",
            "Logistic Regression Accuracy: 0.8696078431372549\n",
            "Random Forest Accuracy: 0.8509803921568627\n",
            "SVM Accuracy: 0.8735294117647059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Assuming `vectorizer` is your TF-IDF vectorizer and `nb_model` is your trained Naive Bayes model\n",
        "\n",
        "# Save the vectorizer and model\n",
        "pickle.dump(vectorizer, open('vector.pkl', 'wb'))\n",
        "pickle.dump(nb_model, open('model.pkl', 'wb'))\n",
        "pickle.dump(label_encoder, open('label_encoder.pkl', 'wb'))\n",
        "\n",
        "print(\"Vectorizer, model, and label encoder saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjbkdOtL57Ov",
        "outputId": "9cd8215c-4308-493e-c57f-32a9b4bbf15d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorizer, model, and label encoder saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_form = pickle.load(open('vector.pkl', 'rb'))\n",
        "load_model = pickle.load(open('model.pkl', 'rb'))\n",
        "loaded_label_encoder = pickle.load(open('label_encoder.pkl', 'rb'))\n",
        "\n",
        "print(\"Vectorizer, model, and label encoder loaded successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laiwqQy-6GW7",
        "outputId": "37082b9c-58a0-4d69-f006-f5425947d760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorizer, model, and label encoder loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_text(text, model, vectorizer):\n",
        "    # Preprocess the input text\n",
        "    processed_text = preprocess_text(text)\n",
        "\n",
        "    # Transform the text into numerical form using the trained vectorizer\n",
        "    text_vector = vectorizer.transform([processed_text]).toarray()\n",
        "\n",
        "    # Predict the category using the trained model\n",
        "    predicted_label = model.predict(text_vector)\n",
        "\n",
        "    # Decode the predicted label to the original category name\n",
        "    predicted_category = label_encoder.inverse_transform(predicted_label)\n",
        "\n",
        "    return predicted_category[0]  # Return the category as a string\n",
        "\n",
        "# Example usage with the Naive Bayes model\n",
        "user_input = \"ग्राहकांना गुणवत्ता आणि सेवा प्रदान करणे महत्त्वाचे आहे.\"\n",
        "predicted_category = classify_text(user_input, nb_model, vectorizer)\n",
        "\n",
        "# Print the result\n",
        "print(f\"Predicted Category: {predicted_category}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtz6hGw23WTi",
        "outputId": "7f8bdf8e-ebe7-4872-e935-4bd4b04f6598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Category: Business\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TVDAzxuy1qkq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}